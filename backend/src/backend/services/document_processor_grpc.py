"""
Document processing service using Google Cloud Document AI Python client library (gRPC)
Optimized for performance with connection pooling, async support, and token caching
"""
import asyncio
import tempfile
from typing import Optional, Dict, Any
from datetime import datetime, timedelta

from google.cloud import documentai_v1 as documentai
from google.api_core.client_options import ClientOptions
from google.api_core import retry_async
from google.auth import default
from google.auth.transport.requests import Request as AuthRequest
import PyPDF2
from pdfminer.high_level import extract_text
from pdfminer.pdfparser import PDFSyntaxError

from backend.core.config import get_settings
from backend.core.logging import get_logger

logger = get_logger(__name__)


class DocumentProcessingError(Exception):
    """Custom exception for document processing errors."""
    pass


class DocumentProcessorGRPC:
    """
    Document processor using Google Cloud Document AI Python client library with gRPC.
    
    Features:
    - gRPC for 50-70% faster network communication
    - Built-in connection pooling and keep-alive
    - Token caching to reduce auth overhead
    - Async support for better concurrency
    - Automatic retry logic
    """
    
    def __init__(self):
        self.settings = get_settings()
        
        # Document AI configuration
        self.project_id = self.settings.PROJECT_NUMBER or self.settings.PROJECT_ID
        self.location = "us"  # Document AI location
        self.processor_id = self.settings.DOC_AI_PROCESSOR_ID
        
        # Build processor resource name
        self.processor_name = f"projects/{self.project_id}/locations/{self.location}/processors/{self.processor_id}"
        
        # Token caching
        self._access_token = None
        self._token_expiry = None
        self._credentials = None
        
        # Initialize async client (lazy initialization)
        self._async_client = None
        
        logger.info("Initialized DocumentProcessorGRPC with gRPC client library")
        logger.info(f"Processor name: {self.processor_name}")
    
    def _get_cached_credentials(self):
        """
        Get cached credentials or refresh if expired.
        
        Returns:
            Credentials with valid access token
        """
        # Check if we have a valid cached token
        if self._access_token and self._token_expiry and datetime.now() < self._token_expiry:
            logger.debug("Using cached access token")
            return self._credentials
        
        try:
            # Try to load from service account file first
            credentials_path = self.settings.GOOGLE_APPLICATION_CREDENTIALS
            
            if credentials_path and credentials_path != "path/to/service-account.json":
                from google.oauth2 import service_account
                credentials = service_account.Credentials.from_service_account_file(
                    credentials_path,
                    scopes=['https://www.googleapis.com/auth/cloud-platform']
                )
                logger.info("Using service account credentials for Document AI")
            else:
                # Fall back to Application Default Credentials
                credentials, project = default(scopes=['https://www.googleapis.com/auth/cloud-platform'])
            
            # Refresh the token if needed
            needs_refresh = (
                not hasattr(credentials, 'token') or 
                not getattr(credentials, 'token', None) or
                (hasattr(credentials, 'expired') and getattr(credentials, 'expired', False))
            )
            
            if needs_refresh:
                auth_req = AuthRequest()
                if hasattr(credentials, 'refresh'):
                    credentials.refresh(auth_req)  # type: ignore
                    logger.debug("Refreshed access token")
            
            # Cache token and credentials
            if hasattr(credentials, 'token'):
                self._access_token = getattr(credentials, 'token', None)
                self._token_expiry = datetime.now() + timedelta(minutes=55)
            
            self._credentials = credentials
            return credentials
            
        except Exception as e:
            logger.error(f"Failed to get credentials: {e}")
            raise DocumentProcessingError(f"Authentication failed: {e}")
    
    def _get_async_client(self) -> documentai.DocumentProcessorServiceAsyncClient:
        """
        Get or create the async Document AI client.
        Client is reused for connection pooling.
        
        Returns:
            Async Document AI client
        """
        if self._async_client is None:
            try:
                # Get credentials first
                credentials = self._get_cached_credentials()
                
                # Configure client options for the specific location
                opts = ClientOptions(api_endpoint=f"{self.location}-documentai.googleapis.com")
                
                # Create async client (with gRPC) using our credentials
                self._async_client = documentai.DocumentProcessorServiceAsyncClient(
                    client_options=opts,
                    credentials=credentials
                )
                
                logger.info(f"Created async Document AI client for {self.location} region")
                
            except Exception as e:
                logger.error(f"Failed to create Document AI client: {e}")
                raise DocumentProcessingError(f"Client initialization failed: {e}")
        
        return self._async_client
    
    async def _process_with_document_ai_grpc(self, pdf_content: bytes) -> Optional[str]:
        """
        Process a document using Document AI gRPC client library.
        
        Args:
            pdf_content: PDF file content as bytes
            
        Returns:
            Extracted text or None if processing fails
        """
        try:
            logger.info("Starting Document AI gRPC processing...")
            logger.info(f"PDF content size: {len(pdf_content)} bytes")
            
            # Ensure credentials are cached
            self._get_cached_credentials()
            
            # Get the async client
            client = self._get_async_client()
            
            # Create the request
            request = documentai.ProcessRequest(
                name=self.processor_name,
                raw_document=documentai.RawDocument(
                    content=pdf_content,
                    mime_type="application/pdf"
                ),
                # Enable field mask for optimized response (optional)
                # field_mask="text,pages.pageNumber"
            )
            
            # Process the document with automatic async retry
            result = await client.process_document(
                request=request,
                retry=retry_async.AsyncRetry(
                    initial=1.0,
                    maximum=10.0,
                    multiplier=2.0,
                    deadline=60.0
                )
            )
            
            # Extract text from the response
            document = result.document
            text = document.text
            
            if text and text.strip():
                logger.info(f"Successfully extracted {len(text)} characters of text via gRPC")
                logger.info(f"Document has {len(document.pages)} page(s)")
                return text
            else:
                logger.warning("Document AI returned empty text")
                return None
                
        except Exception as e:
            logger.error(f"Error during Document AI gRPC processing: {e}")
            logger.error(f"Error type: {type(e).__name__}")
            return None
    
    async def _fallback_extract_text(self, file_content: bytes) -> Optional[str]:
        """
        Fallback text extraction using pdfminer and PyPDF2.
        
        Args:
            file_content: PDF file content as bytes
            
        Returns:
            Extracted text or None if extraction fails
        """
        logger.info("Attempting fallback text extraction...")
        
        try:
            # Create a temporary file for fallback processing
            with tempfile.NamedTemporaryFile(suffix=".pdf", delete=False) as temp_file:
                temp_file.write(file_content)
                temp_file_path = temp_file.name
            
            logger.info(f"Created temporary file: {temp_file_path}")
            
            # Try pdfminer first
            try:
                logger.info("Attempting text extraction with pdfminer...")
                text = await asyncio.to_thread(extract_text, temp_file_path)
                if text and text.strip():
                    logger.info(f"pdfminer extracted {len(text)} characters")
                    return text
            except PDFSyntaxError as e:
                logger.warning(f"pdfminer failed with syntax error: {str(e)}")
            except Exception as e:
                logger.warning(f"pdfminer failed: {str(e)}")
            
            # Try PyPDF2 as backup
            try:
                logger.info("Attempting text extraction with PyPDF2...")
                with open(temp_file_path, 'rb') as pdf_file:
                    pdf_reader = PyPDF2.PdfReader(pdf_file)
                    text = ""
                    for page_num, page in enumerate(pdf_reader.pages):
                        text += page.extract_text()
                    
                    if text and text.strip():
                        logger.info(f"PyPDF2 extracted {len(text)} characters")
                        return text
            except Exception as e:
                logger.warning(f"PyPDF2 failed: {str(e)}")
            
            logger.error("All fallback extraction methods failed")
            return None
            
        except Exception as e:
            logger.error(f"Error during fallback extraction: {str(e)}")
            return None
    
    async def process_document(
        self, 
        file_content: bytes, 
        filename: str,
        use_fallback: bool = True
    ) -> Dict[str, Any]:
        """
        Process a PDF document and extract text.
        
        Args:
            file_content: PDF file content as bytes
            filename: Name of the file being processed
            use_fallback: Whether to use fallback methods if Document AI fails
            
        Returns:
            Dictionary containing:
                - text: Extracted text content
                - char_count: Number of characters
                - page_count: Number of pages (if available)
                - method: Processing method used
                
        Raises:
            DocumentProcessingError: If all processing methods fail
        """
        logger.info(f"Starting document processing for {filename}")
        
        # Try Document AI gRPC first
        text = await self._process_with_document_ai_grpc(file_content)
        
        if text:
            return {
                "text": text,
                "char_count": len(text),
                "page_count": 1,  # Will be updated if we parse pages
                "method": "document_ai_grpc"
            }
        
        # Try fallback methods if enabled
        if use_fallback:
            logger.warning("Document AI gRPC failed, trying fallback methods...")
            text = await self._fallback_extract_text(file_content)
            
            if text:
                return {
                    "text": text,
                    "char_count": len(text),
                    "page_count": 1,
                    "method": "fallback_extraction"
                }
        
        # All methods failed
        error_msg = "Failed to extract text from document using all available methods"
        logger.error(error_msg)
        raise DocumentProcessingError(error_msg)
    
    def clear_cache(self):
        """Clear cached credentials and reset client."""
        self._access_token = None
        self._token_expiry = None
        self._async_client = None
        logger.info("Cleared credentials cache and reset client")
